%Put the BIBTEX data here from Google Scholar to automatically generate references


@article{DBLP:journals/corr/NguyenRSGTMD16,
  author    = {Tri Nguyen and
               Mir Rosenberg and
               Xia Song and
               Jianfeng Gao and
               Saurabh Tiwary and
               Rangan Majumder and
               Li Deng},
  title     = {{MS} {MARCO:} {A} Human Generated MAchine Reading COmprehension Dataset},
  journal   = {CoRR},
  volume    = {abs/1611.09268},
  year      = {2016},
  url       = {http://arxiv.org/abs/1611.09268},
  archivePrefix = {arXiv},
  eprint    = {1611.09268},
  timestamp = {Mon, 13 Aug 2018 16:49:03 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/NguyenRSGTMD16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
}
@misc{modal2024,
  author       = {Modal},
  title        = {Modal - Serverless Framework for AI Workflows},
  year         = {2024},
  url          = {https://modal.com},
  note         = {Accessed: 2024-12-03}
}
@article{pytorch,
  title={Automatic differentiation in PyTorch},
  author={Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
  year={2017}
}
@misc{hyde,
      title={Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks}, 
      author={Patrick Lewis and Ethan Perez and Aleksandra Piktus and Fabio Petroni and Vladimir Karpukhin and Naman Goyal and Heinrich Küttler and Mike Lewis and Wen-tau Yih and Tim Rocktäschel and Sebastian Riedel and Douwe Kiela},
      year={2021},
      eprint={2005.11401},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2005.11401}, 
}

@misc{qwen2.5,
    title = {Qwen2.5: A Party of Foundation Models},
    url = {https://qwenlm.github.io/blog/qwen2.5/},
    author = {Qwen Team},
    month = {September},
    year = {2024}
}

@misc{qwen2,
      title={Qwen2 Technical Report}, 
      author={An Yang and Baosong Yang and Binyuan Hui and Bo Zheng and Bowen Yu and Chang Zhou and Chengpeng Li and Chengyuan Li and Dayiheng Liu and Fei Huang and Guanting Dong and Haoran Wei and Huan Lin and Jialong Tang and Jialin Wang and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Ma and Jin Xu and Jingren Zhou and Jinze Bai and Jinzheng He and Junyang Lin and Kai Dang and Keming Lu and Keqin Chen and Kexin Yang and Mei Li and Mingfeng Xue and Na Ni and Pei Zhang and Peng Wang and Ru Peng and Rui Men and Ruize Gao and Runji Lin and Shijie Wang and Shuai Bai and Sinan Tan and Tianhang Zhu and Tianhao Li and Tianyu Liu and Wenbin Ge and Xiaodong Deng and Xiaohuan Zhou and Xingzhang Ren and Xinyu Zhang and Xipin Wei and Xuancheng Ren and Yang Fan and Yang Yao and Yichang Zhang and Yu Wan and Yunfei Chu and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zhihao Fan},
      journal={arXiv preprint arXiv:2407.10671},
      year={2024}
}

@misc{nvembed,
      title={NV-Embed: Improved Techniques for Training LLMs as Generalist Embedding Models}, 
      author={Chankyu Lee and Rajarshi Roy and Mengyao Xu and Jonathan Raiman and Mohammad Shoeybi and Bryan Catanzaro and Wei Ping},
      year={2024},
      eprint={2405.17428},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2405.17428}, 
}

@article{moreira2024nv,
  title={NV-Retriever: Improving text embedding models with effective hard-negative mining},
  author={Moreira, Gabriel de Souza P and Osmulski, Radek and Xu, Mengyao and Ak, Ronay and Schifferer, Benedikt and Oldridge, Even},
  journal={arXiv preprint arXiv:2407.15831},
  year={2024}
}

@misc{rag,
      title={Precise Zero-Shot Dense Retrieval without Relevance Labels}, 
      author={Luyu Gao and Xueguang Ma and Jimmy Lin and Jamie Callan},
      year={2022},
      eprint={2212.10496},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2212.10496}, 
}
@misc{meditron70b,
      title={MEDITRON-70B: Scaling Medical Pretraining for Large Language Models},
      author={Zeming Chen and Alejandro Hernández Cano and Angelika Romanou and Antoine Bonnet and Kyle Matoba and Francesco Salvi and Matteo Pagliardini and Simin Fan and Andreas Köpf and Amirkeivan Mohtashami and Alexandre Sallinen and Alireza Sakhaeirad and Vinitra Swamy and Igor Krawczuk and Deniz Bayazit and Axel Marmet and Syrielle Montariol and Mary-Anne Hartley and Martin Jaggi and Antoine Bosselut},
      year={2023},
      eprint={2311.16079},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{lora,
      title={LoRA: Low-Rank Adaptation of Large Language Models},
      author={Edward J. Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
      year={2021},
      eprint={2106.09685},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{hendryckstest2021,
  title={Measuring Massive Multitask Language Understanding},
  author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},
  journal={Proceedings of the International Conference on Learning Representations (ICLR)},
  year={2021}
}

@misc{Med-PaLM2,
      title={Towards Expert-Level Medical Question Answering with Large Language Models}, 
      author={Karan Singhal and Tao Tu and Juraj Gottweis and Rory Sayres and Ellery Wulczyn and Le Hou and Kevin Clark and Stephen Pfohl and Heather Cole-Lewis and Darlene Neal and Mike Schaekermann and Amy Wang and Mohamed Amin and Sami Lachgar and Philip Mansfield and Sushant Prakash and Bradley Green and Ewa Dominowska and Blaise Aguera y Arcas and Nenad Tomasev and Yun Liu and Renee Wong and Christopher Semturs and S. Sara Mahdavi and Joelle Barral and Dale Webster and Greg S. Corrado and Yossi Matias and Shekoofeh Azizi and Alan Karthikesalingam and Vivek Natarajan},
      year={2023},
      eprint={2305.09617},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{Transformers,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2023},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@misc{pmc,
title = {PMC open access subset},
author = {{Bethesda (MD): National Library of Medicine}},
year = {2003},
url = {https://www.ncbi.nlm.nih.gov/pmc/tools/openftlist/}
}

@misc{llama3,
title = {NVIDIA NIM API llama3-70b},
author = {NVIDIA},
year = {2024},
url = {https://build.nvidia.com/explore/discover#llama3-70b}
}

@inproceedings{huggingface,
    title = "Transformers: State-of-the-Art Natural Language Processing",
    author = "Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = oct,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-demos.6",
    pages = "38--45"
}
@misc{biomistral,
      title={BioMistral: A Collection of Open-Source Pretrained Large Language Models for Medical Domains}, 
      author={Yanis Labrak and Adrien Bazoge and Emmanuel Morin and Pierre-Antoine Gourraud and Mickael Rouvier and Richard Dufour},
      year={2024},
      eprint={2402.10373},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{openllmleaderboard,
  author = {Ankit Pal and Pasquale Minervini and {Andreas Geert Motzfeldt} and {Beatrice Alex}},
  title = {openlifescienceai/'open\_medical\_llm\_leaderboard'},
  year = {2024},
  publisher = {Hugging Face},
  url = {https://huggingface.co/spaces/openlifescienceai/open\_medical\_llm\_leaderboard}
}

@misc{rerank1,
      title={Large Language Models are Effective Text Rankers with Pairwise Ranking Prompting}, 
      author={Zhen Qin and Rolf Jagerman and Kai Hui and Honglei Zhuang and Junru Wu and Le Yan and Jiaming Shen and Tianqi Liu and Jialu Liu and Donald Metzler and Xuanhui Wang and Michael Bendersky},
      year={2024},
      eprint={2306.17563},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2306.17563}, 
}
@misc{rerank2,
      title={Re-Ranking Step by Step: Investigating Pre-Filtering for Re-Ranking with Large Language Models}, 
      author={Baharan Nouriinanloo and Maxime Lamothe},
      year={2024},
      eprint={2406.18740},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.18740}, 
}
@misc{rerank3,
      title={Open-source Large Language Models are Strong Zero-shot Query Likelihood Models for Document Ranking}, 
      author={Shengyao Zhuang and Bing Liu and Bevan Koopman and Guido Zuccon},
      year={2023},
      eprint={2310.13243},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2310.13243}, 
}
@misc{rerank4,
      title={PaRaDe: Passage Ranking using Demonstrations with Large Language Models}, 
      author={Andrew Drozdov and Honglei Zhuang and Zhuyun Dai and Zhen Qin and Razieh Rahimi and Xuanhui Wang and Dana Alon and Mohit Iyyer and Andrew McCallum and Donald Metzler and Kai Hui},
      year={2023},
      eprint={2310.14408},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2310.14408}, 
}
@misc{ enwiki:1236851603,
      author = "{Wikipedia contributors}",
      title = "Tf–idf --- {Wikipedia}{,} The Free Encyclopedia",
      year = "2024",
      howpublished = "\url{https://en.wikipedia.org/w/index.php?title=Tf%E2%80%93idf&oldid=1236851603}",
      note = "[Online; accessed 21-September-2024]"
}
@misc{ enwiki:1194828429,
      author = "{Wikipedia contributors}",
      title = "Okapi BM25 --- {Wikipedia}{,} The Free Encyclopedia",
      year = "2024",
       howpublished = "\url{https://en.wikipedia.org/w/index.php?title=Okapi_BM25&oldid=1194828429}",
      note = "[Online; accessed 22-September-2024]"
}
