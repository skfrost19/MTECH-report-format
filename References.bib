%Put the BIBTEX data here from Google Scholar to automatically generate references
@misc{meditron70b,
      title={MEDITRON-70B: Scaling Medical Pretraining for Large Language Models},
      author={Zeming Chen and Alejandro Hernández Cano and Angelika Romanou and Antoine Bonnet and Kyle Matoba and Francesco Salvi and Matteo Pagliardini and Simin Fan and Andreas Köpf and Amirkeivan Mohtashami and Alexandre Sallinen and Alireza Sakhaeirad and Vinitra Swamy and Igor Krawczuk and Deniz Bayazit and Axel Marmet and Syrielle Montariol and Mary-Anne Hartley and Martin Jaggi and Antoine Bosselut},
      year={2023},
      eprint={2311.16079},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@misc{lora,
      title={LoRA: Low-Rank Adaptation of Large Language Models},
      author={Edward J. Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
      year={2021},
      eprint={2106.09685},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{hendryckstest2021,
  title={Measuring Massive Multitask Language Understanding},
  author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},
  journal={Proceedings of the International Conference on Learning Representations (ICLR)},
  year={2021}
}

@misc{Med-PaLM2,
      title={Towards Expert-Level Medical Question Answering with Large Language Models}, 
      author={Karan Singhal and Tao Tu and Juraj Gottweis and Rory Sayres and Ellery Wulczyn and Le Hou and Kevin Clark and Stephen Pfohl and Heather Cole-Lewis and Darlene Neal and Mike Schaekermann and Amy Wang and Mohamed Amin and Sami Lachgar and Philip Mansfield and Sushant Prakash and Bradley Green and Ewa Dominowska and Blaise Aguera y Arcas and Nenad Tomasev and Yun Liu and Renee Wong and Christopher Semturs and S. Sara Mahdavi and Joelle Barral and Dale Webster and Greg S. Corrado and Yossi Matias and Shekoofeh Azizi and Alan Karthikesalingam and Vivek Natarajan},
      year={2023},
      eprint={2305.09617},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{Transformers,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2023},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@misc{pmc,
title = {PMC open access subset},
author = {{Bethesda (MD): National Library of Medicine}},
year = {2003},
url = {https://www.ncbi.nlm.nih.gov/pmc/tools/openftlist/}
}

@misc{llama3,
title = {NVIDIA NIM API llama3-70b},
author = {NVIDIA},
year = {2024},
url = {https://build.nvidia.com/explore/discover#llama3-70b}
}

@inproceedings{huggingface,
    title = "Transformers: State-of-the-Art Natural Language Processing",
    author = "Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = oct,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-demos.6",
    pages = "38--45"
}
@misc{biomistral,
      title={BioMistral: A Collection of Open-Source Pretrained Large Language Models for Medical Domains}, 
      author={Yanis Labrak and Adrien Bazoge and Emmanuel Morin and Pierre-Antoine Gourraud and Mickael Rouvier and Richard Dufour},
      year={2024},
      eprint={2402.10373},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{openllmleaderboard,
  author = {Ankit Pal and Pasquale Minervini and {Andreas Geert Motzfeldt} and {Beatrice Alex}},
  title = {openlifescienceai/'open\_medical\_llm\_leaderboard'},
  year = {2024},
  publisher = {Hugging Face},
  url = {https://huggingface.co/spaces/openlifescienceai/open\_medical\_llm\_leaderboard}
}

@misc{rerank1,
      title={Large Language Models are Effective Text Rankers with Pairwise Ranking Prompting}, 
      author={Zhen Qin and Rolf Jagerman and Kai Hui and Honglei Zhuang and Junru Wu and Le Yan and Jiaming Shen and Tianqi Liu and Jialu Liu and Donald Metzler and Xuanhui Wang and Michael Bendersky},
      year={2024},
      eprint={2306.17563},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2306.17563}, 
}
@misc{rerank2,
      title={Re-Ranking Step by Step: Investigating Pre-Filtering for Re-Ranking with Large Language Models}, 
      author={Baharan Nouriinanloo and Maxime Lamothe},
      year={2024},
      eprint={2406.18740},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.18740}, 
}
@misc{rerank3,
      title={Open-source Large Language Models are Strong Zero-shot Query Likelihood Models for Document Ranking}, 
      author={Shengyao Zhuang and Bing Liu and Bevan Koopman and Guido Zuccon},
      year={2023},
      eprint={2310.13243},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2310.13243}, 
}
@misc{rerank4,
      title={PaRaDe: Passage Ranking using Demonstrations with Large Language Models}, 
      author={Andrew Drozdov and Honglei Zhuang and Zhuyun Dai and Zhen Qin and Razieh Rahimi and Xuanhui Wang and Dana Alon and Mohit Iyyer and Andrew McCallum and Donald Metzler and Kai Hui},
      year={2023},
      eprint={2310.14408},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2310.14408}, 
}
@misc{ enwiki:1236851603,
      author = "{Wikipedia contributors}",
      title = "Tf–idf --- {Wikipedia}{,} The Free Encyclopedia",
      year = "2024",
      howpublished = "\url{https://en.wikipedia.org/w/index.php?title=Tf%E2%80%93idf&oldid=1236851603}",
      note = "[Online; accessed 21-September-2024]"
}
@misc{ enwiki:1194828429,
      author = "{Wikipedia contributors}",
      title = "Okapi BM25 --- {Wikipedia}{,} The Free Encyclopedia",
      year = "2024",
       howpublished = "\url{https://en.wikipedia.org/w/index.php?title=Okapi_BM25&oldid=1194828429}",
      note = "[Online; accessed 22-September-2024]"
}
