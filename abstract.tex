%\vspace{-4.0\baselineskip}
%\vspace{4 cm}
%\begin{flushright}
%    {\LARGE \textbf{ABSTRACT}}
%\end{flushright}

%\vspace{-0.5\baselineskip}
%\noindent\rule{\linewidth}{2pt}
\newgeometry{tmargin=2.5cm, lmargin=38mm, rmargin=25mm, bmargin=25mm}
\thispagestyle{empty}
%\vspace*{0.1cm}
\begin{center}
{\underline{\bf\Large ABSTRACT }}\\
\par\vspace{5mm}
\end{center}

This study explores the effectiveness of embedding-based document re-ranking for biomedical information retrieval using different tokenization strategies. We implement large language models (LLMs) to generate semantic embeddings for both documents and queries and re-rank documents based on similarity scores. Our approach systematically compares general-purpose tokenizers with domain-specific ones to assess their impact on re-ranking performance. Additionally, we fine-tune an LLM model on a biomedical corpus to enhance domain-specific relevance. The evaluation includes standard information retrieval metrics, comparing the performance of our approach with baseline methods. By testing various tokenizers and assessing their effect on document ranking, this work aims to optimize re-ranking processes and provide insights into improving search relevance in biomedical applications.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%